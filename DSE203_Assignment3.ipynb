{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63842ee2-b489-42ac-80e8-855a0b79f994",
   "metadata": {},
   "source": [
    "# DSE 203 - Assignment 3\n",
    "## Group 5 - Christopher Vanhook, Vaaruni Desai, Zufeshan Imran\n",
    "### <font color='red'>Query - List all the unincorporated places where there is a cafe</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb6ee7-bbab-4806-a0ff-eedefb933d83",
   "metadata": {},
   "source": [
    "### Install the required libraries for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c65a63-6eb5-49a9-aca6-a85cf6a3fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /home/v1desai/anaconda3/lib/python3.9/site-packages (0.18.0)\n",
      "Requirement already satisfied: python-levenshtein in /home/v1desai/anaconda3/lib/python3.9/site-packages (0.23.0)\n",
      "Requirement already satisfied: psycopg2-binary in /home/v1desai/anaconda3/lib/python3.9/site-packages (2.9.9)\n",
      "Requirement already satisfied: jsonpath_ng in /home/v1desai/anaconda3/lib/python3.9/site-packages (1.6.0)\n",
      "Requirement already satisfied: Levenshtein==0.23.0 in /home/v1desai/anaconda3/lib/python3.9/site-packages (from python-levenshtein) (0.23.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /home/v1desai/anaconda3/lib/python3.9/site-packages (from Levenshtein==0.23.0->python-levenshtein) (3.5.2)\n",
      "Requirement already satisfied: ply in /home/v1desai/anaconda3/lib/python3.9/site-packages (from jsonpath_ng) (3.11)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy python-levenshtein psycopg2-binary jsonpath_ng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e77d2-41e6-4dcc-95b5-07d23c8d2e5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db99bed9-e673-4686-bc1a-a0638c73935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from jsonpath_ng.ext import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66d272-0b34-4e42-bf1a-9a32c2177574",
   "metadata": {
    "tags": []
   },
   "source": [
    "### We're looking at two files. A JSON file containing information about places in San Diego and a CSV file containing information about businesses in and around San Diego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7689be-a1ca-462a-a3ff-a230bc425211",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'statisticalAtlas.json'\n",
    "csv_file = 'nourish_public_ca_business.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0895b9-384c-48d1-a6db-eaeb33bebe57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import CSV into pgadmin and query the required results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95482105-9c0b-40eb-a92c-55e98d4987e1",
   "metadata": {},
   "source": [
    "\n",
    "#### Connect to pgadmin host - The cell takes user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cbca3fb-e799-4530-ad23-bc36009c5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter database name: postgres\n",
      "\n",
      "Enter host name: localhost\n",
      "\n",
      "Enter user name: postgres\n",
      "\n",
      "Enter password: password\n",
      "\n",
      "Enter port number: 5432\n"
     ]
    }
   ],
   "source": [
    "database = input(\"Enter database name:\")\n",
    "host = input(\"\\nEnter host name:\")\n",
    "user = input(\"\\nEnter user name:\")\n",
    "password = input(\"\\nEnter password:\")\n",
    "port = input(\"\\nEnter port number:\")\n",
    "\n",
    "conn = psycopg2.connect(database=database,\n",
    "                        host=host,\n",
    "                        user=user,\n",
    "                        password=password,\n",
    "                        port=port)\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a8ebc-b321-473e-8b44-ed6aec026d57",
   "metadata": {},
   "source": [
    "#### Import csv data into pgadmin. \n",
    "1. Drop the table if it already exists\n",
    "2. Create a table \n",
    "3. Copy/import csv data into respective columns in the created table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5adfcb8-87ce-4ef7-a1c7-61a82f5b3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "DROP_TABLE = \"\"\"DROP table if EXISTS nourish_public \"\"\"\n",
    "cur.execute(DROP_TABLE)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4642ca90-79c2-4f3f-b250-723ce94765b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table\n",
    "CREATE_TABLE = \"\"\"CREATE table IF NOT EXISTS nourish_public\n",
    "(id bigserial primary key,\n",
    " name varchar,\n",
    " address varchar,\n",
    " avg_rating varchar,\n",
    " zip varchar(5),\n",
    " categories text[],\n",
    " city varchar\n",
    ");\"\"\"\n",
    "cur.execute(CREATE_TABLE)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23d033a-6811-4f4b-970e-58ec322823f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from csv file into postgres database into the created table\n",
    "IMPORT_CSV = \"\"\"COPY nourish_public(name,address,avg_rating,zip,categories,city) FROM '/tmp/nourish_public_ca_business.csv' DELIMITER ',' CSV HEADER;\"\"\"\n",
    "cur.execute(IMPORT_CSV)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07082cba-dccd-4c92-a09a-d6d321696b1a",
   "metadata": {},
   "source": [
    "#### SQL Query to extract places where there is a cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b886fa9-4c2e-46af-b8f8-0be36be987f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query Runetime: 402.6651382446289 microseconds\n"
     ]
    }
   ],
   "source": [
    "# Open the cursor, execute the SQL query and close the cursor\n",
    "start_time = time.time()\n",
    "cur =conn.cursor()\n",
    "SQL_QUERY = \"\"\"SELECT * FROM (SELECT *, unnest(categories) as cat FROM nourish_public) s WHERE lower(cat) LIKE '%cafe%';\"\"\"\n",
    "cur.execute(SQL_QUERY)\n",
    "records = cur.fetchall()\n",
    "col_names = [desc[0] for desc in cur.description]\n",
    "cur.close()\n",
    "print(\"SQL Query Runetime: %s microseconds\" % ((time.time() - start_time)*100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8161d-4692-4f09-9f7d-e28d5faaaaac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read JSON, query the required results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a7167-5878-4bc1-8857-3978f417b33a",
   "metadata": {},
   "source": [
    "#### Load in JSON file using json library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9503546-9f03-412e-934e-01a6a116ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file, \"r\") as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab0d56-26be-4ecd-9f23-bc71151db503",
   "metadata": {},
   "source": [
    "#### JSON Query to extract Unincorporated Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb73b58-8dbf-4be0-83f5-2674aaa31685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Query Runetime: 7798.194885253906 microseconds\n"
     ]
    }
   ],
   "source": [
    "# JSONPath expression to get all the Unincorporated places\n",
    "start_time = time.time()\n",
    "jsonpath_expr = parse(\"$.['Unincorporated Places']\")\n",
    "matches = [match.value for match in jsonpath_expr.find(json_data)]\n",
    "print(\"JSON Query Runetime: %s microseconds\" % ((time.time() - start_time)*100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf1f4d-51f9-4222-81dd-66ab4330b062",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Function to create Hash tables for both SQL and JSON data and JOIN them by matching the HASH table keys\n",
    "\n",
    "Regarding the json_csv_hash_join function -\n",
    "Here, the sql key is used to check if it exists in json hash table. Then the json data for that particular key is extracted and stored in result variable. There are cases where the names of cities don't match exactly. \n",
    "For example - JSON data has listed Mount Laguna as 'Mount Laguna' whereas SQL data (csv file) has it listed as Mt. Laguna. \n",
    "For such cases, fuzzywuzzy comes in handy. With a threshold of 85, we were able to extract all the matching records we wanted. \n",
    "\n",
    "Threshold can be adjusted based on the differences in the files that are dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a84b17-d19d-41d8-8ba5-0755cd7607b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create JSON hash table given the json_data and the key name\n",
    "def json_hash(json_file, json_parser_query, json_column_retrieve):\n",
    "    jsonpath_expr = parse(f\"$.['{json_parser_query}']\")\n",
    "    matches = [match.value for match in jsonpath_expr.find(json_file)]\n",
    "    start_time = time.time()\n",
    "    json_hash = {}\n",
    "\n",
    "    for entry in matches[0]:\n",
    "        city_name = entry.get(json_column_retrieve)\n",
    "        if city_name is not None:\n",
    "            if city_name not in json_hash:\n",
    "                json_hash[city_name] = []\n",
    "            json_hash[city_name].append(entry)\n",
    "    print(\"JSON Hash table creation runtime: %s microseconds\" % ((time.time() - start_time)*100000))\n",
    "\n",
    "    return json_hash\n",
    "\n",
    "# Function to create SQL hash table given the sql_data and the index of the item to be used as key\n",
    "def sql_hash(csv_file, column_name):\n",
    "    start_time = time.time()\n",
    "    sql_hash_dict = {}\n",
    "    for entry in records:\n",
    "        city_name = entry[col_names.index(column_name)]\n",
    "        if city_name is not None:\n",
    "            if city_name not in sql_hash_dict:\n",
    "                sql_hash_dict[city_name] = []\n",
    "            sql_hash_dict[city_name].append(entry)\n",
    "    print(\"SQL Hash table creation runtime: %s microseconds\" % ((time.time() - start_time)*100000))\n",
    "    return sql_hash_dict\n",
    "\n",
    "# Join data based on the matching keys and measure the processing time\n",
    "def json_csv_hash_join(json_file, sql_file, column_csv, column_json, json_parser, keys_to_return = {'City Name', 'State', 'County'}):\n",
    "    sql_hash_column = sql_hash(json_file, column_csv)\n",
    "    json_hash_column = json_hash(json_file, json_parser, column_json)\n",
    "    start_time = time.time()\n",
    "    threshold = 85\n",
    "    matching_keys = []\n",
    "    keys_to_return = keys_to_return\n",
    "\n",
    "    for sql_key in sql_hash_column:\n",
    "        match = process.extractOne(sql_key, json_hash_column.keys(), scorer=fuzz.token_sort_ratio)\n",
    "        if match[1] >= threshold:\n",
    "            matching_keys.append({key: json_hash_column[match[0]][0][key] for key in json_hash_column[match[0]][0].keys() & keys_to_return})\n",
    "    time_taken = (time.time() - start_time)\n",
    "    print(f\"Joining Hash tables runtime: {time_taken * 100000} microseconds\")\n",
    "    return matching_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f09ed1c-8b8f-4161-8ca1-b66018a33ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Hash table creation runtime: 5.8650970458984375 microseconds\n",
      "JSON Hash table creation runtime: 2.7418136596679688 microseconds\n",
      "Joining Hash tables runtime: 381.32667541503906 microseconds\n",
      "\n",
      "List of Unincorporated areas where there is a cafe \n",
      "[\n",
      "    {\n",
      "        \"City Name\": \"Rancho Santa Fe\",\n",
      "        \"County\": \"San Diego\",\n",
      "        \"State\": \"California\"\n",
      "    },\n",
      "    {\n",
      "        \"City Name\": \"Pala\",\n",
      "        \"County\": \"San Diego\",\n",
      "        \"State\": \"California\"\n",
      "    },\n",
      "    {\n",
      "        \"City Name\": \"Mount Laguna\",\n",
      "        \"County\": \"San Diego\",\n",
      "        \"State\": \"California\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "result = json_csv_hash_join(json_file = json_data, sql_file = records, column_csv = 'city', column_json = 'City Name', json_parser = 'Unincorporated Places')\n",
    "\n",
    "print(f\"\\nList of Unincorporated areas where there is a cafe \\n{json.dumps(result, sort_keys=True, indent=4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
